{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to pandas\n",
    "\n",
    "This notebook will introduce you to intermediate tasks using the [`pandas`](https://pandas.pydata.org/) data analysis library and demonstrate how to dedupe, clean, group, merge/join and visualize a data set.\n",
    "\n",
    "The data for this exercise will be a CSV of opioid deaths reported in Minnesota. Many examples here are adapted from work by Mary Jo Webster.\n",
    "\n",
    "(If you're completely new to Python or your syntax is rusty, it might be useful to [keep this notebook open in a new tab](Python%20syntax%20cheat%20sheet.ipynb) as a reference.)\n",
    "\n",
    "#### Ssession outline\n",
    "- [Using Jupyter notebooks](#Using-Jupyter-notebooks)\n",
    "- [Import pandas](#Import-pandas)\n",
    "- [Load data into a data frame](#Load-data-into-a-data-frame)\n",
    "- [Inspect the data](#Inspect-the-data)\n",
    "- [Sort the data](#Sort-the-data)\n",
    "- [Filter the data](#Filter-the-data)\n",
    "- [Group and aggregate the data](#Group-and-aggregate-the-data)\n",
    "- [Export to CSV](#Export-to-CSV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For reference: Using Jupyter notebooks\n",
    "\n",
    "There are many ways to write and run Python code on your computer. One way -- the method we're using today -- is to use [Jupyter notebooks](https://jupyter.org/), which run in your browser and allow you to intersperse documentation with your code. They're handy for bundling your code with a human-readable explanation of what's happening at each step. Check out some examples from the [L.A. Times](https://github.com/datadesk/notebooks) and [BuzzFeed News](https://github.com/BuzzFeedNews/everything#data-and-analyses).\n",
    "\n",
    "**To add a new cell to your notebook**: Click the + button in the menu.\n",
    "\n",
    "**To run a cell of code**: Select the cell and click the \"Run\" button in the menu, or you can press Shift+Enter.\n",
    "\n",
    "**One common gotcha**: The notebook doesn't \"know\" about code you've written until you've _run_ the cell containing it. For example, if you define a variable called `my_name` in one cell, and later, when you try to access that variable in another cell but get an error that says `NameError: name 'my_name' is not defined`, the most likely solution is to run (or re-run) the cell in which you defined `my_name`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import pandas; load a csv into a dataram\n",
    "\n",
    "This was covered in more detail in the previous session, so we'll keep moving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATEID</th>\n",
       "      <th>FIRSTNAME</th>\n",
       "      <th>MIDDLENAME</th>\n",
       "      <th>LASTNAME</th>\n",
       "      <th>MAIDENNAME</th>\n",
       "      <th>SUFFIX</th>\n",
       "      <th>BIRTHDATE</th>\n",
       "      <th>DEATHDATE</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>RACE</th>\n",
       "      <th>...</th>\n",
       "      <th>DEATHCOUNTY</th>\n",
       "      <th>MANNERDEATH</th>\n",
       "      <th>INJURY_DATE</th>\n",
       "      <th>INJURYPLACE</th>\n",
       "      <th>INJURYSTATE</th>\n",
       "      <th>INJURYCOUNTY</th>\n",
       "      <th>INJURY_FIPS</th>\n",
       "      <th>INJURYDESC</th>\n",
       "      <th>CAUSEA</th>\n",
       "      <th>CAUSEB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2005-MN-006548</td>\n",
       "      <td>LANCE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CHOMMIE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12/16/1953</td>\n",
       "      <td>2/26/2005</td>\n",
       "      <td>M</td>\n",
       "      <td>White</td>\n",
       "      <td>...</td>\n",
       "      <td>ANOKA</td>\n",
       "      <td>ACCIDENT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DECEDENT INGESTED AN UNKNOWN AMOUNT OF OXYCODONE</td>\n",
       "      <td>OXYCODONE TOXICITY</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2005-MN-009829</td>\n",
       "      <td>CARRIE</td>\n",
       "      <td>ANNE</td>\n",
       "      <td>FISCHER</td>\n",
       "      <td>HOLMES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6/6/1961</td>\n",
       "      <td>3/27/2005</td>\n",
       "      <td>F</td>\n",
       "      <td>White</td>\n",
       "      <td>...</td>\n",
       "      <td>ANOKA</td>\n",
       "      <td>ACCIDENT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DECEDENT INJESTED AN UNKNOWN AMOUNT OF MORPHINE</td>\n",
       "      <td>MORPHINE TOXICITY</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2005-MN-023540</td>\n",
       "      <td>ELLIS</td>\n",
       "      <td>RAY</td>\n",
       "      <td>MCGHEE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4/4/1963</td>\n",
       "      <td>7/4/2005</td>\n",
       "      <td>M</td>\n",
       "      <td>African American</td>\n",
       "      <td>...</td>\n",
       "      <td>ANOKA</td>\n",
       "      <td>ACCIDENT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNSPECIFIED PLACE</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>THE DECEDENT INGESTED AN UNKNOWN AMOUNT OF COC...</td>\n",
       "      <td>MIXED DRUG TOXICITY (COCAINE AND MORPHINE)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2005-MN-027612</td>\n",
       "      <td>NATHANIEL</td>\n",
       "      <td>RYE</td>\n",
       "      <td>HAMILTON</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8/14/1976</td>\n",
       "      <td>9/25/2005</td>\n",
       "      <td>M</td>\n",
       "      <td>White</td>\n",
       "      <td>...</td>\n",
       "      <td>ANOKA</td>\n",
       "      <td>ACCIDENT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>THE DECEDENT INGESTED AN UNKNOWN AMOUNT OF OXY...</td>\n",
       "      <td>MIXED DRUG TOXICITY (OXYCODONE AND ALPRAZOLAM)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2005-MN-028477</td>\n",
       "      <td>JILL</td>\n",
       "      <td>KRISTINA</td>\n",
       "      <td>BROWN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4/14/1982</td>\n",
       "      <td>10/3/2005</td>\n",
       "      <td>F</td>\n",
       "      <td>White</td>\n",
       "      <td>...</td>\n",
       "      <td>ANOKA</td>\n",
       "      <td>SUICIDE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DEC INGESTED AN UNKNOWN AMOUNT OF SEROQUEL AND...</td>\n",
       "      <td>QUETIAPINE AND OXYCODONE TOXICITY</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3802</th>\n",
       "      <td>2016-MN-029127</td>\n",
       "      <td>STEPHEN</td>\n",
       "      <td>KIRK</td>\n",
       "      <td>PATTERSON</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3/2/1987</td>\n",
       "      <td>8/31/2016</td>\n",
       "      <td>M</td>\n",
       "      <td>White</td>\n",
       "      <td>...</td>\n",
       "      <td>WRIGHT</td>\n",
       "      <td>ACCIDENT</td>\n",
       "      <td>8/31/2016</td>\n",
       "      <td>PRIVATE RESIDENCE</td>\n",
       "      <td>MINNESOTA</td>\n",
       "      <td>WRIGHT</td>\n",
       "      <td>27171.0</td>\n",
       "      <td>THE DECEDENT SELF-ADMINISTERED HEROIN AND ETHANOL</td>\n",
       "      <td>MIXED HEROIN AND ALCOHOL TOXICITY</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3803</th>\n",
       "      <td>2017-MN-018317</td>\n",
       "      <td>TIMOTHY</td>\n",
       "      <td>ROBERT</td>\n",
       "      <td>WARD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4/13/1966</td>\n",
       "      <td>5/26/2017</td>\n",
       "      <td>M</td>\n",
       "      <td>White</td>\n",
       "      <td>...</td>\n",
       "      <td>WRIGHT</td>\n",
       "      <td>ACCIDENT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PRIVATE RESIDENCE</td>\n",
       "      <td>MINNESOTA</td>\n",
       "      <td>WRIGHT</td>\n",
       "      <td>27171.0</td>\n",
       "      <td>THE DECEDENT SELF-ADMINISTERED EXCESSIVE OXYCO...</td>\n",
       "      <td>OXYCODONE OVERDOSE</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3804</th>\n",
       "      <td>2017-MN-024845</td>\n",
       "      <td>AUSTIN</td>\n",
       "      <td>ADRIAN</td>\n",
       "      <td>HILL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12/5/1996</td>\n",
       "      <td>7/23/2017</td>\n",
       "      <td>M</td>\n",
       "      <td>White</td>\n",
       "      <td>...</td>\n",
       "      <td>WRIGHT</td>\n",
       "      <td>ACCIDENT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PRIVATE RESIDENCE</td>\n",
       "      <td>MINNESOTA</td>\n",
       "      <td>WRIGHT</td>\n",
       "      <td>27171.0</td>\n",
       "      <td>THE DECEDENT USED ILLICIT FENTANYL</td>\n",
       "      <td>FENTANYL TOXICITY</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3805</th>\n",
       "      <td>2014-MN-009504</td>\n",
       "      <td>STEPHANIE</td>\n",
       "      <td>PAIGE</td>\n",
       "      <td>LABATTE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/14/1984</td>\n",
       "      <td>3/23/2014</td>\n",
       "      <td>F</td>\n",
       "      <td>American Indian</td>\n",
       "      <td>...</td>\n",
       "      <td>YELLOW MEDICINE</td>\n",
       "      <td>ACCIDENT</td>\n",
       "      <td>3/23/2014</td>\n",
       "      <td>PROJECT TURNABOUT</td>\n",
       "      <td>MINNESOTA</td>\n",
       "      <td>YELLOW MEDICINE</td>\n",
       "      <td>27173.0</td>\n",
       "      <td>OVERDOSE OF FENTANYL.  STEPHANIE LABATTE INGES...</td>\n",
       "      <td>OVERDOSE OF FENTANYL</td>\n",
       "      <td>DEPRESSION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3806</th>\n",
       "      <td>2014-MN-039821</td>\n",
       "      <td>LISA</td>\n",
       "      <td>LYNN</td>\n",
       "      <td>LALIM</td>\n",
       "      <td>LALIM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2/27/1971</td>\n",
       "      <td>12/20/2014</td>\n",
       "      <td>F</td>\n",
       "      <td>White</td>\n",
       "      <td>...</td>\n",
       "      <td>YELLOW MEDICINE</td>\n",
       "      <td>SUICIDE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>MINNESOTA</td>\n",
       "      <td>YELLOW MEDICINE</td>\n",
       "      <td>27173.0</td>\n",
       "      <td>THE DECEASED INGESTED AN EXCESS OF THE ABOVE S...</td>\n",
       "      <td>MIXED DRUG TOXICITY (TRAMADOL, DIPHENHYDRAMINE...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3807 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             STATEID  FIRSTNAME MIDDLENAME   LASTNAME MAIDENNAME SUFFIX  \\\n",
       "0     2005-MN-006548      LANCE        NaN    CHOMMIE        NaN    NaN   \n",
       "1     2005-MN-009829     CARRIE       ANNE    FISCHER     HOLMES    NaN   \n",
       "2     2005-MN-023540      ELLIS        RAY     MCGHEE        NaN    NaN   \n",
       "3     2005-MN-027612  NATHANIEL        RYE   HAMILTON        NaN    NaN   \n",
       "4     2005-MN-028477       JILL   KRISTINA      BROWN        NaN    NaN   \n",
       "...              ...        ...        ...        ...        ...    ...   \n",
       "3802  2016-MN-029127    STEPHEN       KIRK  PATTERSON        NaN    NaN   \n",
       "3803  2017-MN-018317    TIMOTHY     ROBERT       WARD        NaN    NaN   \n",
       "3804  2017-MN-024845     AUSTIN     ADRIAN       HILL        NaN    NaN   \n",
       "3805  2014-MN-009504  STEPHANIE      PAIGE    LABATTE        NaN    NaN   \n",
       "3806  2014-MN-039821       LISA       LYNN      LALIM      LALIM    NaN   \n",
       "\n",
       "       BIRTHDATE   DEATHDATE GENDER              RACE  ...      DEATHCOUNTY  \\\n",
       "0     12/16/1953   2/26/2005      M             White  ...            ANOKA   \n",
       "1       6/6/1961   3/27/2005      F             White  ...            ANOKA   \n",
       "2       4/4/1963    7/4/2005      M  African American  ...            ANOKA   \n",
       "3      8/14/1976   9/25/2005      M             White  ...            ANOKA   \n",
       "4      4/14/1982   10/3/2005      F             White  ...            ANOKA   \n",
       "...          ...         ...    ...               ...  ...              ...   \n",
       "3802    3/2/1987   8/31/2016      M             White  ...           WRIGHT   \n",
       "3803   4/13/1966   5/26/2017      M             White  ...           WRIGHT   \n",
       "3804   12/5/1996   7/23/2017      M             White  ...           WRIGHT   \n",
       "3805   1/14/1984   3/23/2014      F   American Indian  ...  YELLOW MEDICINE   \n",
       "3806   2/27/1971  12/20/2014      F             White  ...  YELLOW MEDICINE   \n",
       "\n",
       "      MANNERDEATH INJURY_DATE        INJURYPLACE INJURYSTATE     INJURYCOUNTY  \\\n",
       "0        ACCIDENT         NaN            UNKNOWN     UNKNOWN          UNKNOWN   \n",
       "1        ACCIDENT         NaN            UNKNOWN     UNKNOWN          UNKNOWN   \n",
       "2        ACCIDENT         NaN  UNSPECIFIED PLACE     UNKNOWN          UNKNOWN   \n",
       "3        ACCIDENT         NaN            UNKNOWN     UNKNOWN          UNKNOWN   \n",
       "4         SUICIDE         NaN            UNKNOWN     UNKNOWN          UNKNOWN   \n",
       "...           ...         ...                ...         ...              ...   \n",
       "3802     ACCIDENT   8/31/2016  PRIVATE RESIDENCE   MINNESOTA           WRIGHT   \n",
       "3803     ACCIDENT         NaN  PRIVATE RESIDENCE   MINNESOTA           WRIGHT   \n",
       "3804     ACCIDENT         NaN  PRIVATE RESIDENCE   MINNESOTA           WRIGHT   \n",
       "3805     ACCIDENT   3/23/2014  PROJECT TURNABOUT   MINNESOTA  YELLOW MEDICINE   \n",
       "3806      SUICIDE         NaN            UNKNOWN   MINNESOTA  YELLOW MEDICINE   \n",
       "\n",
       "     INJURY_FIPS                                         INJURYDESC  \\\n",
       "0            NaN   DECEDENT INGESTED AN UNKNOWN AMOUNT OF OXYCODONE   \n",
       "1            NaN    DECEDENT INJESTED AN UNKNOWN AMOUNT OF MORPHINE   \n",
       "2            NaN  THE DECEDENT INGESTED AN UNKNOWN AMOUNT OF COC...   \n",
       "3            NaN  THE DECEDENT INGESTED AN UNKNOWN AMOUNT OF OXY...   \n",
       "4            NaN  DEC INGESTED AN UNKNOWN AMOUNT OF SEROQUEL AND...   \n",
       "...          ...                                                ...   \n",
       "3802     27171.0  THE DECEDENT SELF-ADMINISTERED HEROIN AND ETHANOL   \n",
       "3803     27171.0  THE DECEDENT SELF-ADMINISTERED EXCESSIVE OXYCO...   \n",
       "3804     27171.0                 THE DECEDENT USED ILLICIT FENTANYL   \n",
       "3805     27173.0  OVERDOSE OF FENTANYL.  STEPHANIE LABATTE INGES...   \n",
       "3806     27173.0  THE DECEASED INGESTED AN EXCESS OF THE ABOVE S...   \n",
       "\n",
       "                                                 CAUSEA      CAUSEB  \n",
       "0                                    OXYCODONE TOXICITY         NaN  \n",
       "1                                     MORPHINE TOXICITY         NaN  \n",
       "2            MIXED DRUG TOXICITY (COCAINE AND MORPHINE)         NaN  \n",
       "3        MIXED DRUG TOXICITY (OXYCODONE AND ALPRAZOLAM)         NaN  \n",
       "4                     QUETIAPINE AND OXYCODONE TOXICITY         NaN  \n",
       "...                                                 ...         ...  \n",
       "3802                  MIXED HEROIN AND ALCOHOL TOXICITY         NaN  \n",
       "3803                                 OXYCODONE OVERDOSE         NaN  \n",
       "3804                                  FENTANYL TOXICITY         NaN  \n",
       "3805                               OVERDOSE OF FENTANYL  DEPRESSION  \n",
       "3806  MIXED DRUG TOXICITY (TRAMADOL, DIPHENHYDRAMINE...         NaN  \n",
       "\n",
       "[3807 rows x 34 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('opiate_deaths.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the data\n",
    "\n",
    "Let's quickly check what columns are in our data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['STATEID', 'FIRSTNAME', 'MIDDLENAME', 'LASTNAME', 'MAIDENNAME',\n",
       "       'SUFFIX', 'BIRTHDATE', 'DEATHDATE', 'GENDER', 'RACE',\n",
       "       'HISPANICETHNICITY', 'AGEYEARS', 'RESADDRESS', 'RESSTATE', 'RESCITY',\n",
       "       'RESCOUNTY', 'ZIP', 'ARMEDFORCES', 'YEARSEDUCATION', 'OCCUPATION',\n",
       "       'INDUSTRY', 'MARITALSTATUS', 'PLACETYPE', 'DEATHCITY', 'DEATHCOUNTY',\n",
       "       'MANNERDEATH', 'INJURY_DATE', 'INJURYPLACE', 'INJURYSTATE',\n",
       "       'INJURYCOUNTY', 'INJURY_FIPS', 'INJURYDESC', 'CAUSEA', 'CAUSEB'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and see how many rows and columns are in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3807, 34)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning your data\n",
    "\n",
    "When you receive data, it will almost always need some cleanup to be ready for analysis and/or display. There are some common issues to look for when you have acquired a new dataset.\n",
    "\n",
    "- Duplicate records\n",
    "- Misspellings\n",
    "- Inconsistent category/variable names\n",
    "- Null or empty (`''`) values that may affect calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for duplicate records with `groupby()`\n",
    "\n",
    "Each record has a `STATEID`, which seems to imply that each row represents a unique death. But how do we know? We can use the `groupby()` method to count how many times each `STATEID` value appears. If each row is a unique person or case, there should be only 1 copy of each value.\n",
    "\n",
    "In pandas we can chain several methods together to achieve our desired output.\n",
    "\n",
    "Here's the full command (we'll break down the details next):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATEID</th>\n",
       "      <th>DEATHCITY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2005-MN-000344</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2543</th>\n",
       "      <td>2014-MN-037772</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2531</th>\n",
       "      <td>2014-MN-035649</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2532</th>\n",
       "      <td>2014-MN-035971</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2533</th>\n",
       "      <td>2014-MN-036080</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1273</th>\n",
       "      <td>2010-MN-035079</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274</th>\n",
       "      <td>2010-MN-035176</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1275</th>\n",
       "      <td>2010-MN-035257</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1276</th>\n",
       "      <td>2010-MN-035518</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3806</th>\n",
       "      <td>2017-MN-044531</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3807 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             STATEID  DEATHCITY\n",
       "0     2005-MN-000344          1\n",
       "2543  2014-MN-037772          1\n",
       "2531  2014-MN-035649          1\n",
       "2532  2014-MN-035971          1\n",
       "2533  2014-MN-036080          1\n",
       "...              ...        ...\n",
       "1273  2010-MN-035079          1\n",
       "1274  2010-MN-035176          1\n",
       "1275  2010-MN-035257          1\n",
       "1276  2010-MN-035518          1\n",
       "3806  2017-MN-044531          1\n",
       "\n",
       "[3807 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['STATEID', 'DEATHCITY']].groupby('STATEID').count().reset_index().sort_values('DEATHCITY', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Groupby, one piece at a time\n",
    "\n",
    "First, let's run our groupby on a subset of the data:\n",
    "\n",
    "`df[['STATEID', 'DEATHCITY']]`\n",
    "\n",
    "This will return a view of the dataframe that only includes the STATEID and DEATHCITY columns.\n",
    "\n",
    "Why do we even need `DEATHCITY` in this case? Because `groupby()` calls need at least two fields to work right. One or more fields that we are grouping on (`STATEID` in this case), and another field to be counted.\n",
    "\n",
    "`df[['STATEID', 'DEATHCITY']].groupby('STATEID')`\n",
    "\n",
    "And we'll add a `count()` call to tell pandas that we want to count the number of rows in each group, as opposed to other methods like summing or finding the average of that group.\n",
    "\n",
    "`df[['STATEID', 'DEATHCITY']].groupby('STATEID').count()`\n",
    "\n",
    "Next we need to include a weird pandas thing, `reset_index()` This is because otherwise, when performing a groupby, pandas will produce a MultiIndex, which is more complex than we need.\n",
    "\n",
    "`df[['STATEID', 'DEATHCITY']].groupby('STATEID').count().reset_index()`\n",
    "\n",
    "And finally we'll sort the results by our counted column, `DEATHCITY`. We want to surface any non-unique `STATEID`s, so we'll sort in descending order.\n",
    "\n",
    "`df[['STATEID', 'DEATHCITY']].groupby('STATEID').count().reset_index().sort_values('DEATHCITY', ascending=False)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great news, the highest count is 1, meaning there are no `STATEID`s that occur more than once."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✍️ Your turn\n",
    "\n",
    "Let's find out how many deaths occured in each city. Take the next few minutes to see if you can group the datafame by the `DEATHCITY` column and count the number of rows from each city.\n",
    "\n",
    "Here's a start for you to build on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "deaths_by_city = df[['DEATHCITY', 'STATEID']]  # Your code herey..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renaming a column\n",
    "\n",
    "It's confusing that the count of cities is held in a column called `STATEID`, which doesn't really have any meaning. It's always a good idea to have column headers that you can clearly understand, so let's rename the `STATEID` column in our `groupby()` to `death_count`. Note that this does NOT change the `STATEID` column in the original dataframe, as we are now working on a copy of a subset of that original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DEATHCITY</th>\n",
       "      <th>death_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>MINNEAPOLIS</td>\n",
       "      <td>829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>SAINT PAUL</td>\n",
       "      <td>285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>DULUTH</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>SAINT CLOUD</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>ROCHESTER</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>MOOSE LAKE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>MORRILL TOWNSHIP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>MORRISTOWN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>MORTON</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADAMS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>415 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            DEATHCITY  death_count\n",
       "241       MINNEAPOLIS          829\n",
       "341        SAINT PAUL          285\n",
       "98             DULUTH          138\n",
       "337       SAINT CLOUD           93\n",
       "325         ROCHESTER           89\n",
       "..                ...          ...\n",
       "249        MOOSE LAKE            1\n",
       "251  MORRILL TOWNSHIP            1\n",
       "253        MORRISTOWN            1\n",
       "254            MORTON            1\n",
       "0               ADAMS            1\n",
       "\n",
       "[415 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deaths_by_city.rename(columns={'STATEID': 'death_count'}, inplace=True)\n",
    "deaths_by_city"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recoding data with `lambda()`\n",
    "\n",
    "We can also use pandas to change the data values to something more presentable or consistent. For example, let's look at the unique values for the `GENDER` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['M', 'F'], dtype=object)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.GENDER.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's change all the values in `GENDER` to the slightly more user-friendly `Male` and `Female`. We'll use a lambda function. A lambda function is shorthand way of writing what you would like to do to each row of data in this column. It's usually safer to add a new column than to change the underlying data, so we'll create a new column called `gender_clean`, and populate it with values from the `GENDER` column that we have run through our little lambda factory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         Male\n",
       "1       Female\n",
       "2         Male\n",
       "3         Male\n",
       "4       Female\n",
       "         ...  \n",
       "3802      Male\n",
       "3803      Male\n",
       "3804      Male\n",
       "3805    Female\n",
       "3806    Female\n",
       "Name: gender_clean, Length: 3807, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['gender_clean'] = df['GENDER'].apply(lambda x: 'Male' if x == 'M' else 'Female')\n",
    "df['gender_clean']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, each row was either labeled M or F, but our basic `if this, else that` logic is too naive for most real-world situations. For example, what if some rows had a value of `NA` or were null? In the above function, those rows would have gotten erroneously marked as `Female`. That's correction waiting to happen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A slightly more complex `lambda()`\n",
    "\n",
    "To introduce more complex logic, we'll still use a lambda(). But instead of cramming the logic of what we want to do into one line, we'll use the lambda to apply an external function to each row.\n",
    "\n",
    "Here's the function we'll apply to each row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_gender(input):\n",
    "    if input == 'M':\n",
    "        return 'Male'\n",
    "    elif input == 'F':\n",
    "        return 'Female'\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may not have thought of every possible exception, but at least we won't wrongly assign some values to either male or female.\n",
    "\n",
    "Now let's apply the `decode_gender` function to each row's `GENDER` column using lambda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      Male\n",
       "1    Female\n",
       "Name: gender_clean, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['gender_clean'] = df['GENDER'].apply(lambda x: decode_gender(x))\n",
    "df['gender_clean'].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning up inconsistent values\n",
    "\n",
    "Now let's take a look at the values in the `HISPANICETHNICITY` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NOT HISPANIC', 'HISPANIC', 'UNKNOWN', 'non-hispanic', 'hispanic',\n",
       "       'NON-HISPANIC', 'not hispanic', 'NOT-HISPANIC'], dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.HISPANICETHNICITY.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whoa, kind of a mess! We can't easily groupby these values right now because of the inconsistent capitalization and spelling.\n",
    "\n",
    "One way to harmonize data in a column is to set all of the letters to uppercase. We'll start a new `hispanic_clean` column to avoid introducing errors into our original `HISPANICETHNICITY` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NOT HISPANIC', 'HISPANIC', 'UNKNOWN', 'NON-HISPANIC',\n",
       "       'NOT-HISPANIC'], dtype=object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['hispanic_clean'] = df['HISPANICETHNICITY'].str.upper()\n",
    "df['hispanic_clean'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, we cut our 8 unique values down to 5. But we still have inconsistencies in the spelling and hyphenation.\n",
    "\n",
    "Let's deal with the simple hyphens first, by searching for and replacing instances of `NON HISPANIC`, sans hyphen. You'll notice that now we're modifying `hispanic_clean`, which we just created, directly. If we ran this against the original `HISPANICETHNICITY` column, we'd mess up some of our previous work on `hispanic_clean`.\n",
    "\n",
    "Like most search and replace functions, the arguments passed to `replace()` are writtin the order of `1. Needle` in the `2. Haystack` you are searching through."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NON-HISPANIC', 'HISPANIC', 'UNKNOWN'], dtype=object)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['hispanic_clean'] = df['hispanic_clean'].str.replace('NON HISPANIC', 'NON-HISPANIC')\n",
    "df['hispanic_clean'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better again! Now let's tackle the `NOT HISPANIC` rows, some of which have a hyphen and some that don't. We could write two lines that are similar to what we just did, but let's throw in a regular expression that can account for cases both with and without the hyphen.\n",
    "\n",
    "`.replace(r'NOT(-| )HISPANIC', 'NON-HISPANIC')`\n",
    "\n",
    "The `r` preceding the string tells python this is a regular expression, not a normal string.\n",
    "\n",
    "The `(-| )` means that either a hypen or a space is an acceptable value to call a match. In either case, the command will write `NON-HISPANIC` instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NON-HISPANIC', 'HISPANIC', 'UNKNOWN'], dtype=object)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['hispanic_clean'] = df['hispanic_clean'].str.replace(r'NOT(-| )HISPANIC', 'NON-HISPANIC')\n",
    "df['hispanic_clean'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What a tidy column we have now!\n",
    "\n",
    "### ✍️ Your turn\n",
    "\n",
    "In the cell below, group by and count the `df` data frame:\n",
    "- Get a subset of the `df` data frame\n",
    "- Group by `hispanic_clean`\n",
    "- Count the rows with each value\n",
    "- Order descending\n",
    "- Rename the count to a new variable called `death_count` after grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deaths_by_hispanic_ethnicity = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our data, the vast majority of deaths are from people without Hispanic ethnicity. But Minnesota is a pretty white state, so we need to look at these numbers as a percentage, so we can compare the deaths to Minnesota's overall Hispanic population, which is about 5% of the state's total population, according to Pew Research.\n",
    "\n",
    "We can create a new column to calculate the percentage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deaths_by_hispanic_ethnicity['pct_total'] = deaths_by_hispanic_ethnicity['death_count'] / deaths_by_hispanic_ethnicity['death_count'].sum()\n",
    "deaths_by_hispanic_ethnicity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the data with a bar chart\n",
    "\n",
    "Pandas works well with a visualization package called [`matplotlib`](https://matplotlib.org/). There are several other visualization packages that have robust feature sets, including Altair, but matplotlib is already tightly integrated with pandas, so we'll start with that.\n",
    "\n",
    "It doesn't make for the most compelling chart in the world, but once you have your data cleaned up, it's easy to make a simple bar chart:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'deaths_by_hispanic_ethnicity' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-bc1ad904b0e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdeaths_by_hispanic_ethnicity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'hispanic_clean'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'death_count'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'deaths_by_hispanic_ethnicity' is not defined"
     ]
    }
   ],
   "source": [
    "deaths_by_hispanic_ethnicity.plot.bar(x='hispanic_clean', y='death_count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting year from a date\n",
    "\n",
    "To look at the trend in deaths over time, we can grab just the year from the `DEATHDATE` column by taking advantage of Python's date-handling abilities. First we need to tell pandas the the `DEATHDATE` column is a `datetime`, not just an ordinary string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DEATHDATE'] = pd.to_datetime(df['DEATHDATE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use `lambda` to call `.year` on each `DEATHDATE`, and pipe it to a new column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2005\n",
       "1       2005\n",
       "2       2005\n",
       "3       2005\n",
       "4       2005\n",
       "        ... \n",
       "3802    2016\n",
       "3803    2017\n",
       "3804    2017\n",
       "3805    2014\n",
       "3806    2014\n",
       "Name: death_year, Length: 3807, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['death_year'] = df['DEATHDATE'].apply(lambda x: x.year)\n",
    "df['death_year']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✍️ Your turn\n",
    "\n",
    "In the cells below, group by and count the `df` data frame:\n",
    "- Get a subset of the `df` data frame\n",
    "- Group by `death_year`\n",
    "- Count the rows with each value\n",
    "- Order by death year\n",
    "- Rename the count to a new variable called `death_count` after grouping\n",
    "- Plot the death years on a bar chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging with other data\n",
    "\n",
    "Of course, it's not surprising that Minnesota's largest city has the highest raw death count -- there are so many more people. The data would be a lot more meaningful if we could calculate the deaths per capita. But population isn't in our original CSV. But we can join our data with other data sources, provided they have some kind of identical value to join on.\n",
    "\n",
    "First, we load a spreadsheet of population data from a reliable source from a similar time period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'mn_cities_townships_pop_estimates.csv' does not exist: b'mn_cities_townships_pop_estimates.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-498102a2f5cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpop_estimates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mn_cities_townships_pop_estimates.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpop_estimates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/teaching-guide-data-cleaning-and-viz-with--eMwggdO_/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/teaching-guide-data-cleaning-and-viz-with--eMwggdO_/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/teaching-guide-data-cleaning-and-viz-with--eMwggdO_/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/teaching-guide-data-cleaning-and-viz-with--eMwggdO_/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/teaching-guide-data-cleaning-and-viz-with--eMwggdO_/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'mn_cities_townships_pop_estimates.csv' does not exist: b'mn_cities_townships_pop_estimates.csv'"
     ]
    }
   ],
   "source": [
    "pop_estimates = pd.read_csv('mn_cities_townships_pop_estimates.csv')\n",
    "pop_estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# If we need another example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping values into new categories\n",
    "\n",
    "For a more informative bar chart, let's tag each row with a new `age_group` value. We can use `lambda()` and `apply()`, as we did above.\n",
    "\n",
    "First, our function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_age_group(age):\n",
    "    if age < 20:\n",
    "        return '0-19'\n",
    "    elif age >=20 and age < 35:\n",
    "        return '20-34'\n",
    "    elif age >= 35 and age < 50:\n",
    "        return '35-49'\n",
    "    elif age >= 50 and age < 70:\n",
    "        return '50-69'\n",
    "    elif age >= 70:\n",
    "        return '70 and over'\n",
    "    return 'Unknown'    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now let's apply it to each row's `AGEYEARS` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age_group'] = df.AGEYEARS.apply(lambda x: get_age_group(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And be sure to check that the results make sense..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_group</th>\n",
       "      <th>AGEYEARS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50-69</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35-49</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35-49</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20-34</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20-34</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3802</th>\n",
       "      <td>20-34</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3803</th>\n",
       "      <td>50-69</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3804</th>\n",
       "      <td>20-34</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3805</th>\n",
       "      <td>20-34</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3806</th>\n",
       "      <td>35-49</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3807 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age_group  AGEYEARS\n",
       "0        50-69        51\n",
       "1        35-49        43\n",
       "2        35-49        42\n",
       "3        20-34        29\n",
       "4        20-34        23\n",
       "...        ...       ...\n",
       "3802     20-34        29\n",
       "3803     50-69        51\n",
       "3804     20-34        20\n",
       "3805     20-34        30\n",
       "3806     35-49        43\n",
       "\n",
       "[3807 rows x 2 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['age_group', 'AGEYEARS']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✍️ Your turn\n",
    "\n",
    "In the cells below, group by and count the `df` data frame:\n",
    "- Get a subset of the `df` data frame\n",
    "- Group by `age_group`\n",
    "- Count the rows with each value\n",
    "- Order by age group\n",
    "- Rename the count to a new variable called `death_count` after grouping\n",
    "- Plot the age groups on a bar chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import pandas\n",
    "\n",
    "Before you can use the functionality of `pandas`, a third-party library installed separately from Python, you need to _import_ it. The convention is to import the library under an alias that's easier to type: `as pd`.\n",
    "\n",
    "Run this cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change a display setting\n",
    "\n",
    "Run the next cell to change a setting that displays big numbers in scientific notation by default. (Unless scientific notation is your jam, in which case _avoid_ running the next cell.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pandas.pydata.org/pandas-docs/stable/user_guide/options.html\n",
    "pd.options.display.float_format = '{:20,.2f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data into a data frame\n",
    "\n",
    "Before you can start poking at a data file, you need to load the data into a pandas _data frame_, which is sort of like a virtual spreadsheet with columns and rows.\n",
    "\n",
    "You can load many different types of data files into a data frame, including CSVs (and other delimited text files), Excel files, JSON [and more](https://www.cbtnuggets.com/blog/2018/10/14-file-types-you-can-import-into-pandas/). ([Here's a quick reference notebook](https://github.com/ireapps/cfj-2018/blob/master/reference/Importing%20data%20into%20pandas.ipynb) demonstrating how to import some different data files, including live data from the Internet!)\n",
    "\n",
    "For today, we'll focus on importing the MLB salary data using a pandas method called [`read_csv()`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html). There are a ton of options you can supply when you read in the data file, but at minimum, you need to tell the method _where_ the file lives, which means you need to supply the path to the data file as a Python _string_ (some text enclosed in single or double quotes). The file is called `mlb.csv`, and it is located in the same directory as this notebook file, so we don't need to specify a longer path.\n",
    "\n",
    "As we import the data, we'll also _assign_ the results of the loading operation to a new variable called _df_ (short for data frame -- easy to type, plus you'll see this pattern a lot when Googling around for help).\n",
    "\n",
    "👉 [Click here for more information on Python variables](Python%20syntax%20cheat%20sheet.ipynb#Variable-assignment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('mlb.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a human sentence: \"Go to the pandas library that we imported earlier as something called `pd` and use its `read_csv()` method to import a file called `mlb.csv` into a data frame -- and while we're at it, assign the results of that operation to a new variable called `df`.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the data\n",
    "\n",
    "Let's take a look at what we've got using a few built-in methods and attributes of a pandas data frame:\n",
    "- `df.head()` will display the first five records (or, if you prefer, you can specify a number, e.g., `df.head(10)`)\n",
    "- `df.tail()` will display the last five records (or, if you prefer, you can specify a number, e.g., `df.tail(10)`)\n",
    "- `df.describe()` will compute summary stats on numeric columns\n",
    "- `df.sample()` will return a randomly selected record (or, if you prefer, you specify a number, e.g., `df.sample(5)`\n",
    "- `df.shape` will tell you how many columns, how many rows\n",
    "- `df.dtypes` will list the column names and tell you what kind of data is in each one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort the data\n",
    "\n",
    "To sort a data frame, use the `sort_values()` method. At a minimum, you need to tell it which column to sort on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values('SALARY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To sort descending, you need to pass in another argument to the `sort_values()` method: `ascending=False`. Note that the boolean value is _not_ a string, so it's not contained in quotes, and only the initial letter is capitalized. (If you are supplying multiple arguments to a function or method, separate them with commas.)\n",
    "\n",
    "👉 [Click here for more information on Python booleans](Python%20syntax%20cheat%20sheet.ipynb#Booleans)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values('SALARY', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use a process called \"method chaining\" to perform multiple operations in one line. If, for instance, we wanted to sort the data frame by salary descending and inspect the first 5 records returned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values('SALARY', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can sort by multiple columns by passing in a _list_ of column names rather than the name of a single column. A list is a collection of items enclosed within square brackets `[]`.\n",
    "\n",
    "👉 [Click here for more information on Python lists](Python%20syntax%20cheat%20sheet.ipynb#Lists).\n",
    "\n",
    "To sort first by `SALARY`, then by `TEAM`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(['SALARY', 'TEAM']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can specify the sort order (descending vs. ascending) for each sort column by passing another list to the `ascending` keyword with `True` and `False` items corresponding to the position of the columns in the first list. \n",
    "\n",
    "For example, to sort by `SALARY` descending, then by `TEAM` ascending:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(['SALARY', 'TEAM'], ascending=[False, True]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `False` goes with `SALARY` and the `True` with `TEAM` because they're in the same position in their respective lists."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One other note: Despite all of this sorting we've been doing, the original `df` data frame is unchanged:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's because we haven't \"saved\" the results of those sorts by assigning them to a new variable. Typically, if you want to preserve a sort (or any other kind of manipulation), you'd would assign the results to a new variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_by_team = df.sort_values('TEAM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_by_team.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✍️ Your turn\n",
    "\n",
    "In the cells below, practice sorting the `df` data frame:\n",
    "- By `NAME`\n",
    "- By `POS` descending\n",
    "- By `SALARY` descending, then by `POS` ascending, and save the results to a new variable called `sorted_by_salary_then_pos`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter the data\n",
    "\n",
    "Let's go over two different kinds of filtering:\n",
    "\n",
    "- Column filtering: Grabbing one or more columns of data to look at, like passing column names to a `SELECT` statement in SQL.\n",
    "- Row filtering: Looking at a subset of your data that matches some criteria, like the crieria following a `WHERE` statement in SQL. (For instance, \"Show me all records in my data frame where the value in the `TEAM` column is \"ARI\".)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Column filtering\n",
    "\n",
    "To access the values in a single column of data, you can use \"dot notation\" as long as the column name doesn't have spaces or other special characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.TEAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otherwise, use \"bracket notation\" with the name of the column as a string.\n",
    "\n",
    "This is equivalent to the previous command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TEAM']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you access a single column in your data frame, you're getting back something called a `Series` object (as opposed to a `DataFrame` object).\n",
    "\n",
    "One of the methods you can call on a Series is `unique()`, which shows you each unique value in the column. Let's do that with the `TEAM` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.TEAM.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we just did is the equivalent of dragging the \"TEAM\" column name into the \"rows\" area of a spreadsheet pivot table, or, in SQL,\n",
    "\n",
    "```sql\n",
    "SELECT DISTINCT TEAM\n",
    "FROM mlb\n",
    "```\n",
    "\n",
    "You can also count up a total for each value using the `value_counts()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.TEAM.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For numeric columns, you can call methods on that Series to compute basic summary stats:\n",
    "- `min()` to get the lowest value\n",
    "- `max()` to get the greatest value\n",
    "- `median()` to get the median\n",
    "- `mean()` to get the average\n",
    "- `mode()` to get the most common value\n",
    "\n",
    "Check it out for the `SALARY` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.SALARY.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.SALARY.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.SALARY.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.SALARY.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.SALARY.mode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To select multiple columns in your data frame, use bracket notation but pass in a _list_ of column names instead of just one. To make things clearer, you could break this out into two steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_we_care_about = ['TEAM', 'SALARY']\n",
    "df[columns_we_care_about]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Row filtering\n",
    "\n",
    "To make things maximally confusing, you _also_ use bracket notation for row filtering. Except in this case, instead of dropping the name of a column (or a list of column names) into the brackets, you hand it a _condition_ of some sort.\n",
    "\n",
    "Let's filter our data to see players who make more than $1 million (in other words, return rows of data where the value in the `SALARY` column is greater than 1000000):\n",
    "\n",
    "(The equivalent SQL statement would be:\n",
    "```sql\n",
    "SELECT *\n",
    "FROM mlb\n",
    "WHERE SALARY > 1000000\n",
    "```\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.SALARY > 1000000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For many filters, you'll use Python's comparison operators:\n",
    "- `>` greater than\n",
    "- `>=` greater than or equal to\n",
    "- `<` less than\n",
    "- `<=` less than or equal to\n",
    "- `==` equal to\n",
    "- `!=` not equal to\n",
    "\n",
    "#### Multiple filter conditions\n",
    "\n",
    "What if you want to use multiple filtering conditions? There is a way, but it usually makes more sense -- and is much easier for your colleagues and your future self to think about and debug -- to _save_ the results of each filtering operation by assigning the results to a new variable, then filter _that_ again instead of the original data frame.\n",
    "\n",
    "For example, if you wanted to look at Colorado Rockies players who make more than $1 million, you might do something like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rockies = df[df.TEAM == 'COL']\n",
    "rockies_over_1m = rockies[rockies.SALARY > 1000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rockies_over_1m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "👉 [Check out some other filtering operations here]()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✍️ Your turn\n",
    "\n",
    "In the cells below, practice filtering:\n",
    "- Column filtering: Select the `NAME` column\n",
    "- Column filtering: Select the `NAME` and `TEAM` columns\n",
    "- Row filtering: Filter the rows to return only players who make the league minimum (535000)\n",
    "- Row filtering: Filter the rows to return only catchers (`C`) who make at least 750000\n",
    "- BONUS: Filter the rows to return only players for the Chicago Cubs (`CHC`), then use method chaining to order the results by `SALARY` descending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group and aggregate the data\n",
    "\n",
    "Data frames have a `groupby` method for grouping and aggregating data, similar to what you might do in a pivot table or a `GROUP BY` statement in SQL. (They also have a [`pivot_table` method](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.pivot_table.html), which can be homework for you to research.)\n",
    "\n",
    "Let's say we wanted to see the top 10 teams by payroll. In other words, we want to:\n",
    "- Group the data by the `TEAM` column: `groupby()`\n",
    "- Add up the records in each group: `sum()`\n",
    "- Sort the results by `SALARY` descending: `sort_values()`\n",
    "- Take only the top 10 results: `head(10)`\n",
    "\n",
    "Calling the `groupby()` method without telling it what to do with the grouped records isn't super helpful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('TEAM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, it's basically telling us that it has successfully grouped the records -- now what? Using method chaining, describe what you would like to _do_ with the numeric columns once you've grouped the data. Let's start with `sum()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('TEAM').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neat! Except it's summing _every_ numeric column, not just `SALARY`. To deal with this, use column filtering to select the two columns we're interested in -- `TEAM` for grouping and `SALARY` for summing -- and _then_ tack on the `groupby` statement, etc.\n",
    "\n",
    "(Remember: To select columns from a data frame, use bracket notation and hand it a _list_ of column names.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['TEAM', 'SALARY']].groupby('TEAM').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bang bang. Now, using method chaining, let's sort by `SALARY` descending and look at just the top 10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['TEAM', 'SALARY']].groupby('TEAM').sum().sort_values('SALARY', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use aggregation methods other than `sum()` -- `mean()` and `median()`, for instance -- or you can use [the `agg()` method](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.agg.html) to specify one or more aggregation methods to apply."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['TEAM', 'SALARY']].groupby('TEAM').median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['TEAM', 'SALARY']].groupby('TEAM').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['TEAM', 'SALARY']].groupby('TEAM').agg(['sum', 'mean', 'median'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✍️ Your turn\n",
    "\n",
    "In the cells below, practice grouping data:\n",
    "- What's the median salary for each position? Group the data by `POS` and aggregate by `median()`, then sort by `SALARY` descending\n",
    "- What's the average salary on each team? Group the data by `TEAM` and aggregate by `sum()`, then sort by `SALARY` descending\n",
    "- What else?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export to CSV\n",
    "\n",
    "To export a dataframe to a delimited text file, use the [`to_csv()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_csv.html) method. If you don't want to include the index numbers, specify `index=False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('my-cool-data-frame.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
